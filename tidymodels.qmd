---
title: "Machine learning in R with tidymodels"
output: html_document
editor: visual
---

*The tidymodels framework is a collection of packages for machine learning using tidyverse principles. tidymodels offers a consistent, flexible framework to streamline data preparation, model selection, training, and evaluation. This template includes all relevant packages and sample code to get you started with a basic machine learning workflow.*

```{r load-tidymodels}
#| message: false
#| warning: false
library(tidymodels)
library(ranger)
```

In this example analysis, let's fit a model to predict [the sex of penguins](https://allisonhorst.github.io/palmerpenguins/) from species and measurement information. We'll use a version of the linked data with missing values omitted, saved as a file in the project folder `data/`:

```{r load-penguins}
#| message: false
#| warning: false
library(readr)

penguins <-
  read_csv("data/penguins.csv") %>%
  mutate(across(where(is.character), as.factor))
```

## Explore data

Exploratory data analysis (EDA) is an [important part of the modeling process](https://www.tmwr.org/software-modeling.html#model-phases). Plotting some of our variables:

```{r plot-penguins}
penguins %>%
  ggplot(aes(bill_depth_mm, bill_length_mm, color = sex, size = body_mass_g)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  theme_bw()
```

## Build models

Let's consider how to [spend our data budget](https://www.tmwr.org/splitting.html):

-   create training and testing sets
-   create resampling folds from the *training* set

```{r split-penguins}
set.seed(123)
penguin_split <- initial_split(penguins)
penguin_train <- training(penguin_split)
penguin_test <- testing(penguin_split)

set.seed(234)
penguin_folds <- vfold_cv(penguin_train)
penguin_folds
```

Now, creating a [**model specification**](https://www.tmwr.org/models.html) for each model we want to try:

```{r model-specs}
glm_spec <- logistic_reg()
rf_spec  <- rand_forest(trees = 1e3) %>% set_mode("classification")
```

To quickly template your modeling code, you can use the [parsnip addin](https://parsnip.tidymodels.org/reference/parsnip_addin.html) or the [usemodels](https://usemodels.tidymodels.org/) package.

Now, let's build a [**model workflow**](https://www.tmwr.org/workflows.html) combining each model specification with a data preprocessor:

```{r model-workflows}
penguin_formula <- sex ~ .

glm_wf <- workflow(penguin_formula, glm_spec)
rf_wf  <- workflow(penguin_formula, rf_spec)
```

If your feature engineering needs are more complex than provided by a formula like `sex ~ .`, use a [recipe](https://www.tidymodels.org/start/recipes/). [Read more about feature engineering with recipes](https://www.tmwr.org/recipes.html) to learn about how they work.

## Evaluate models

These models have no tuning parameters so we can evaluate them as they are. [Learn about tuning hyperparameters here](https://www.tidymodels.org/start/tuning/).

```{r resample-models}
glm_rs <- fit_resamples(glm_wf, penguin_folds)
rf_rs  <- fit_resamples(rf_wf, penguin_folds)
```

How did these two models compare?

```{r collect-metrics-resampled}
collect_metrics(glm_rs)
collect_metrics(rf_rs)
```

These models perform very similarly, so perhaps we would choose the simpler, linear model. The function `last_fit()` *fits* one final time on the training data and *evaluates* on the testing data. Note that this is the first time we have used the testing data.

```{r last-fit}
final_fitted <- last_fit(glm_wf, penguin_split)
```

The following are the metrics for the *testing* data:

```{r collect-metrics-final}
collect_metrics(final_fitted)
```

This object contains a fitted workflow that we can use for prediction.

```{r predict-final}
final_wf <- extract_workflow(final_fitted)

predict(final_wf, penguin_test[55,])
```

You can save this fitted `final_wf` object to use later with new data, for example with `write_rds()`, or deploy it with [vetiver](https://vetiver.rstudio.com/).
